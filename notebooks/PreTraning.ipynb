{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Yim-dgWUyA_S"
      },
      "outputs": [],
      "source": [
        "# Unlabled Raw Text\n",
        "\n",
        "text = \"\"\"\n",
        "  your journey starts with one step\n",
        "  your journeu starts today\n",
        "  one step can change everything\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def build_dataset(text, block_size):\n",
        "    tokens = [stoi[w] for w in text.split()]\n",
        "    X, Y = [], []\n",
        "\n",
        "    for i in range(len(tokens) - block_size):\n",
        "        X.append(tokens[i:i+block_size])\n",
        "        Y.append(tokens[i+1:i+block_size+1])\n",
        "\n",
        "    return torch.tensor(X), torch.tensor(Y)\n"
      ],
      "metadata": {
        "id": "Exi_moOm4kqH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "airRON414mp-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, block_size):\n",
        "        super().__init__()\n",
        "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_emb = nn.Embedding(block_size, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T = x.shape\n",
        "        pos = torch.arange(T)\n",
        "        return self.token_emb(x) + self.pos_emb(pos)\n"
      ],
      "metadata": {
        "id": "PdBknPaC4otQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_model, 4*d_model),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4*d_model, d_model)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "DzNcXXcr4qXP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "        self.num_heads = num_heads\n",
        "        self.d_head = d_model // num_heads\n",
        "\n",
        "        self.qkv = nn.Linear(d_model, 3*d_model, bias=False)\n",
        "        self.out = nn.Linear(d_model, d_model, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "\n",
        "        qkv = self.qkv(x)\n",
        "        Q, K, V = qkv.chunk(3, dim=-1)\n",
        "\n",
        "        Q = Q.view(B, T, self.num_heads, self.d_head).transpose(1, 2)\n",
        "        K = K.view(B, T, self.num_heads, self.d_head).transpose(1, 2)\n",
        "        V = V.view(B, T, self.num_heads, self.d_head).transpose(1, 2)\n",
        "\n",
        "        scores = (Q @ K.transpose(-2, -1)) / (self.d_head ** 0.5)\n",
        "\n",
        "        mask = torch.triu(torch.ones(T, T), diagonal=1)\n",
        "        scores = scores.masked_fill(mask == 1, float('-inf'))\n",
        "\n",
        "        attn = F.softmax(scores, dim=-1)\n",
        "        out = attn @ V\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous().view(B, T, C)\n",
        "        return self.out(out)\n"
      ],
      "metadata": {
        "id": "WeR9mQX_4sIU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTBlock(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.attn = MultiHeadSelfAttention(d_model, num_heads)\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "        self.mlp = FeedForward(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.ln1(x))\n",
        "        x = x + self.mlp(self.ln2(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "MkXCOWP44txY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniGPT(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, block_size, num_heads, num_layers):\n",
        "        super().__init__()\n",
        "        self.embed = GPTEmbedding(vocab_size, d_model, block_size)\n",
        "        self.blocks = nn.Sequential(\n",
        "            *[GPTBlock(d_model, num_heads) for _ in range(num_layers)]\n",
        "        )\n",
        "        self.ln_f = nn.LayerNorm(d_model)\n",
        "        self.lm_head = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x, targets=None):\n",
        "        x = self.embed(x)\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(\n",
        "                logits.view(-1, vocab_size),\n",
        "                targets.view(-1)\n",
        "            )\n",
        "\n",
        "        return logits, loss\n"
      ],
      "metadata": {
        "id": "A2SsaXoY4wH2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = text.strip().split()\n",
        "vocab = sorted(list(set(words)))\n",
        "stoi = {s:i for i,s in enumerate(vocab)}\n",
        "itos = {i:s for i,s in enumerate(vocab)}\n",
        "vocab_size = len(vocab)\n",
        "block_size = 8 # A common choice for block_size\n",
        "\n",
        "model = MiniGPT(\n",
        "    vocab_size=vocab_size,\n",
        "    d_model=64,\n",
        "    block_size=block_size,\n",
        "    num_heads=4,\n",
        "    num_layers=2\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n"
      ],
      "metadata": {
        "id": "Ihgosxwg5PKH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = build_dataset(text, block_size)\n",
        "\n",
        "for step in range(500):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    logits, loss = model(X, Y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 100 == 0:\n",
        "        print(f\"step {step} | loss {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OV4mRQf15RFQ",
        "outputId": "f4cdb093-521f-44cf-b1ba-3797c475390b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0 | loss 2.5572\n",
            "step 100 | loss 0.1258\n",
            "step 200 | loss 0.0561\n",
            "step 300 | loss 0.0428\n",
            "step 400 | loss 0.0369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h0ai5rWT5WBN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}